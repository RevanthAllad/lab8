{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cba31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability for buys_computer = yes: 0.643\n",
      "Prior Probability for buys_computer = no: 0.357\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "data = [\n",
    "    ['<=30', 'high', 'no', 'fair', 'no'],\n",
    "    ['<=30', 'high', 'no', 'excellent', 'no'],\n",
    "    ['31...40', 'high', 'no', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'no', 'fair', 'yes'],\n",
    "    ['>40', 'low', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'low', 'yes', 'excellent', 'no'],\n",
    "    ['31...40', 'low', 'yes', 'excellent', 'yes'],\n",
    "    ['<=30', 'medium', 'no', 'fair', 'no'],\n",
    "    ['<=30', 'low', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'yes', 'fair', 'yes'],\n",
    "    ['<=30', 'medium', 'yes', 'excellent', 'yes'],\n",
    "    ['31...40', 'medium', 'no', 'excellent', 'yes'],\n",
    "    ['31...40', 'high', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'no', 'excellent', 'no']\n",
    "]\n",
    "\n",
    "# Count instances for each class\n",
    "class_counts = {'yes': 0, 'no': 0}\n",
    "for instance in data:\n",
    "    buys_computer = instance[-1]\n",
    "    class_counts[buys_computer] += 1\n",
    "\n",
    "# Calculate prior probabilities\n",
    "total_instances = len(data)\n",
    "prior_prob_yes = class_counts['yes'] / total_instances\n",
    "prior_prob_no = class_counts['no'] / total_instances\n",
    "\n",
    "# Print the results\n",
    "print(f'Prior Probability for buys_computer = yes: {prior_prob_yes:.3f}')\n",
    "print(f'Prior Probability for buys_computer = no: {prior_prob_no:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be08ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class conditional density for feature 1, value 31...40, class yes:\n",
      "4\n",
      "\n",
      "Class conditional density for feature 1, value >40, class yes:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 1, value <=30, class yes:\n",
      "2\n",
      "\n",
      "Class conditional density for feature 1, value >40, class no:\n",
      "2\n",
      "\n",
      "Class conditional density for feature 1, value <=30, class no:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 2, value high, class yes:\n",
      "2\n",
      "\n",
      "Class conditional density for feature 2, value medium, class yes:\n",
      "4\n",
      "\n",
      "Class conditional density for feature 2, value low, class yes:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 2, value high, class no:\n",
      "2\n",
      "\n",
      "Class conditional density for feature 2, value medium, class no:\n",
      "2\n",
      "\n",
      "Class conditional density for feature 2, value low, class no:\n",
      "1\n",
      "\n",
      "Class conditional density for feature 3, value no, class yes:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 3, value yes, class yes:\n",
      "6\n",
      "\n",
      "Class conditional density for feature 3, value no, class no:\n",
      "4\n",
      "\n",
      "Class conditional density for feature 3, value yes, class no:\n",
      "1\n",
      "\n",
      "Class conditional density for feature 4, value excellent, class yes:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 4, value fair, class yes:\n",
      "6\n",
      "\n",
      "Class conditional density for feature 4, value excellent, class no:\n",
      "3\n",
      "\n",
      "Class conditional density for feature 4, value fair, class no:\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "# (your dataset definition here)\n",
    "\n",
    "# Separate data by class\n",
    "data_by_class = {'yes': [], 'no': []}\n",
    "for instance in data:\n",
    "    buys_computer = instance[-1]\n",
    "    data_by_class[buys_computer].append(instance)\n",
    "\n",
    "# Calculate class conditional densities for each feature and class\n",
    "class_conditional_densities = {}\n",
    "for feature_index in range(len(data[0]) - 1):  # Exclude the target class in the last column\n",
    "    for buys_computer in ['yes', 'no']:\n",
    "        feature_values = [instance[feature_index] for instance in data_by_class[buys_computer]]\n",
    "        unique_values = set(feature_values)\n",
    "\n",
    "        for value in unique_values:\n",
    "            # Filter out '31...40' and non-numeric values\n",
    "            feature_data = [float(instance[feature_index]) for instance in data_by_class[buys_computer] if instance[feature_index] == value and instance[feature_index].replace('.', '').replace('...','').isdigit() and instance[feature_index] != '31...40']\n",
    "\n",
    "            if feature_data:\n",
    "                # For continuous features, fit a normal distribution\n",
    "                pdf_params = norm.fit(feature_data)\n",
    "                pdf = norm.pdf(np.linspace(min(feature_data), max(feature_data), 100), *pdf_params)\n",
    "\n",
    "                # Check if any class conditional density has zero values\n",
    "                if any(pdf == 0):\n",
    "                    print(f\"Warning: Class conditional density for feature {feature_index + 1}, value {value}, class {buys_computer} has zero values.\")\n",
    "\n",
    "                class_conditional_densities[(feature_index + 1, value, buys_computer)] = pdf\n",
    "            else:\n",
    "                # For discrete features, count occurrences\n",
    "                count = feature_values.count(value)\n",
    "                class_conditional_densities[(feature_index + 1, value, buys_computer)] = count\n",
    "\n",
    "# Print the results (class conditional densities)\n",
    "for key, value in class_conditional_densities.items():\n",
    "    print(f\"Class conditional density for feature {key[0]}, value {key[1]}, class {key[2]}:\")\n",
    "    print(value)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4c62f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Value: 11.277167277167278\n",
      "P-value: 0.08017877950576319\n",
      "Fail to reject the null hypothesis: There is no significant evidence of dependence between the features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define the dataset\n",
    "# (your dataset definition here)\n",
    "\n",
    "# Select the relevant columns for testing independence\n",
    "selected_features = [0, 1, 2, 3]  # Adjust these indices based on your dataset\n",
    "selected_data = np.array([[instance[i] for i in selected_features] for instance in data])\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = []\n",
    "max_len = 0  # Initialize the maximum length\n",
    "for i in range(len(selected_features)):\n",
    "    feature_values = set(selected_data[:, i])\n",
    "    counts = [np.sum(selected_data[:, i] == value) for value in feature_values]\n",
    "    \n",
    "    # Update the maximum length\n",
    "    max_len = max(max_len, len(counts))\n",
    "    \n",
    "    contingency_table.append(counts)\n",
    "\n",
    "# Pad the counts lists with zeros to make them uniform\n",
    "contingency_table = [counts + [0] * (max_len - len(counts)) for counts in contingency_table]\n",
    "\n",
    "# Convert the contingency table to a NumPy array\n",
    "contingency_table = np.array(contingency_table)\n",
    "\n",
    "# Perform the chi-square test of independence\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# Check the significance level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: There is evidence of dependence between the features.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant evidence of dependence between the features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dc26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
